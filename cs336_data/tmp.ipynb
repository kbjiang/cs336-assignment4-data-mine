{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3ca71e1",
   "metadata": {},
   "source": [
    "## Parse and extract text from `warc` file\n",
    "1. With `fastwarc` and `resiliparse`\n",
    "    1. https://resiliparse.chatnoir.eu/en/stable/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58b5770",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastwarc import ArchiveIterator\n",
    "from resiliparse.extract.html2text import extract_plain_text\n",
    "from resiliparse.parse.encoding import detect_encoding\n",
    "\n",
    "def extract_text(record):\n",
    "    byte_string = record.reader.read()\n",
    "    encoding = detect_encoding(byte_string)\n",
    "    html_content = byte_string.decode(encoding=encoding)\n",
    "    extracted_text = extract_plain_text(html_content)\n",
    "    return extracted_text\n",
    "\n",
    "warc_file = \"/home/azureuser/localfiles/cs336-assignment4-data-mine/cs336_data/CC-MAIN-20250417135010-20250417165010-00065.warc.gz\"\n",
    "iterator = ArchiveIterator(open(warc_file, \"rb\"), func_filter=lambda r: r.headers.get('WARC-Identified-Payload-Type') == 'text/html')\n",
    "\n",
    "# record = next(iterator)\n",
    "# print(extract_text(record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebca25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get random records for ensuing tests\n",
    "# Method: Skip randomly through iterator\n",
    "import random\n",
    "\n",
    "def get_random_records(iterator, N=20, skip_prob=0.9):\n",
    "    \"\"\"Skip records randomly and return extracted text immediately\"\"\"\n",
    "    random_data = []\n",
    "    for i, record in enumerate(iterator):\n",
    "        if len(random_data) >= N:\n",
    "            break\n",
    "        if random.random() > skip_prob:\n",
    "            # Read and process immediately while record is still fresh\n",
    "            extracted_text = extract_text(record)\n",
    "            random_data.append((i, extracted_text))\n",
    "    return random_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f449b6",
   "metadata": {},
   "source": [
    "## Language identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d05aa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "model = fasttext.load_model(\"lid.176.bin\")\n",
    "\n",
    "# sanity check\n",
    "model.predict(\"Hello world.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe62814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_generator():\n",
    "    for i, text in random_data:\n",
    "        print(f\"=== Record {i} ===\")\n",
    "        print(text[:200] + \"...\" if len(text) > 200 else text)\n",
    "        lang, score = model.predict(text.replace(\"\\n\", \" \"))\n",
    "        print(f\"Language: {lang[0]}, Score: {score[0]:.4f}\")\n",
    "        print(\"-\" * 50)\n",
    "        yield \n",
    "\n",
    "# Get random records with extracted text\n",
    "random_data = get_random_records(iterator)\n",
    "\n",
    "# Create the generator\n",
    "lang_gen = language_generator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dbf177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell multiple times to get one result at a time\n",
    "next(lang_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc4f272",
   "metadata": {},
   "source": [
    "## PII\n",
    "### email address\n",
    "- Length: The total length of an email address is capped at 320 characters, with 64 for the username and 255 for the domain.\n",
    "- Spaces: Spaces are not allowed.\n",
    "- Case sensitivity: Email addresses are generally not case-sensitive, meaning User@Example.com is the same as user@example.com.\n",
    "\n",
    "- Special characters:\n",
    "    - Periods (.), hyphens (-), and underscores (_) are often allowed in the local part.\n",
    "    - They cannot be the first or last character of the local part and cannot appear consecutively (e.g., john..doe@example.com is invalid).\n",
    "    - In the domain, hyphens are allowed but not at the beginning or end of a label (a part between periods). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3161958",
   "metadata": {},
   "source": [
    "### US phone number\n",
    "1. use pattern\n",
    "    - (\\+1\\s*)? - optional `+1` followed by optional spaces\n",
    "    - \\(? - optional opening parenthesis\n",
    "    - \\d{3} - 3 digits\n",
    "    - \\)? - optional closing parenthesis\n",
    "    - [\\s-]? - at most one space or hyphen (the ? means zero or one)\n",
    "    - \\s* - zero or more additional spaces\n",
    "    - \\d{3} - 3 digits\n",
    "    - [\\s-]? - at most one space or hyphen\n",
    "    - \\s* - zero or more additional spaces\n",
    "    - \\d{4} - 4 digits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3691ca",
   "metadata": {},
   "source": [
    "### IP address\n",
    "- Use `\\b` to avoid matching things like:\n",
    "    - 1.2.3.4.5 (too many octets)\n",
    "    - version1.2.3.4 (prefix attached)\n",
    "    - 1.2.3.4th (suffix attached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580a8216",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mask_pii import mask_email, mask_phone, mask_ip\n",
    "\n",
    "record = next(iterator)\n",
    "text = extract_text(record)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26db5fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text, mask_email_counts = mask_email(text)\n",
    "text, mask_phone_counts = mask_phone(text)\n",
    "text, mask_ip_counts = mask_ip(text)\n",
    "\n",
    "if any([counts > 0 for counts in [mask_email_counts, mask_phone_counts, mask_ip_counts]]):\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7d571a",
   "metadata": {},
   "source": [
    "## Harmful content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe55101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "\n",
    "model = fasttext.load_model(\"/home/azureuser/localfiles/cs336-assignment4-data-mine/cs336_data/jigsaw_fasttext_bigrams_nsfw_final.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1964b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\n",
    "    \"SUCK MY C*CK WIKIPEDIA EDITORS...F*CKING *SSH*LE DORKS. \"\n",
    "    \"JUST TRYING TO MAKE THE SITE BETTER YOU UPTIGHT C*NTS\"\n",
    ")\n",
    "# text = \"Umm, theres no actual article for prostitution ring.  - Crunch Captain.\"\n",
    "text = \"操你妈 你个傻逼 干死你\"\n",
    "\n",
    "model.predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df020d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b548985e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from harmful_content import classify_nsfw, classify_toxic_speech\n",
    "\n",
    "found = False\n",
    "while found == False:\n",
    "    record = next(iterator)\n",
    "    try:\n",
    "        text = extract_text(record)\n",
    "    except UnicodeDecodeError:\n",
    "        continue\n",
    "    # print(text)\n",
    "    is_nsfw, score_nsfw = classify_nsfw(text)\n",
    "    is_toxic, score_toxic = classify_toxic_speech(text)\n",
    "\n",
    "    if is_nsfw == \"nsfw\" or is_toxic == \"toxic\":\n",
    "        print(text)\n",
    "        print(\"=\"*80)\n",
    "        print(\"Harmful content detected!\")\n",
    "        print(is_nsfw, is_toxic)\n",
    "        print(score_nsfw, score_toxic)\n",
    "\n",
    "        found = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fbea20",
   "metadata": {},
   "source": [
    "## Quality Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fedcbfc",
   "metadata": {},
   "source": [
    "- To get `warc` file\n",
    "    - `wget --tries=2 --timeout=5 -i enwiki-20240420-extracted_urls_subset.txt --warc-file=subsampled_positive_urls -O /dev/null`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f5bf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastwarc import ArchiveIterator\n",
    "from fastwarc.warc import WarcRecord\n",
    "from resiliparse.extract.html2text import extract_plain_text\n",
    "from resiliparse.parse.encoding import detect_encoding\n",
    "\n",
    "def extract_text(record):\n",
    "    byte_string = record.reader.read()\n",
    "    encoding = detect_encoding(byte_string)\n",
    "    try:\n",
    "        html_content = byte_string.decode(encoding=encoding)\n",
    "    except UnicodeDecodeError:\n",
    "        return \"\"\n",
    "    extracted_text = extract_plain_text(html_content)\n",
    "    return extracted_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0813af3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_html_record(record: WarcRecord) -> bool:\n",
    "    try:\n",
    "        return record.http_headers.get('Content-Type', '').startswith('text/html')\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "warc_file = \"/home/azureuser/localfiles/cs336-assignment4-data-mine/cs336_data/subsampled_positive_urls.warc.gz\"\n",
    "iterator = ArchiveIterator(open(warc_file, \"rb\"))\n",
    "\n",
    "from language_identification import identify_language\n",
    "positive_texts = []\n",
    "for record in iterator:\n",
    "    if is_html_record(record):\n",
    "        text = extract_text(record)\n",
    "        if len(text) > 512:\n",
    "            lang, score = identify_language(text)\n",
    "            if lang == \"en\" and score > 0.8:\n",
    "                positive_texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc27014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from language_identification import identify_language\n",
    "\n",
    "def get_random_english_records(iterator, N=600, skip_prob=0.8):\n",
    "    \"\"\"Skip records randomly and return extracted text immediately\"\"\"\n",
    "    random_data = []\n",
    "    for record in iterator:\n",
    "        if len(random_data) >= N:\n",
    "            break\n",
    "        if random.random() > skip_prob:\n",
    "            # Read and process immediately while record is still fresh\n",
    "            extracted_text = extract_text(record)\n",
    "            lang, score = identify_language(extracted_text)\n",
    "            if lang == \"en\" and score > 0.8:\n",
    "                random_data.append(extracted_text)\n",
    "    return random_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba68d4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "warc_file = \"/home/azureuser/localfiles/cs336-assignment4-data-mine/cs336_data/CC-MAIN-20250417135010-20250417165010-00065.warc.gz\"\n",
    "iterator = ArchiveIterator(open(warc_file, \"rb\"), func_filter=lambda r: r.headers.get('WARC-Identified-Payload-Type') == 'text/html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6bf16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_texts = get_random_english_records(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28534234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save to pickle file\n",
    "with open('positive_texts.pkl', 'wb') as f:\n",
    "    pickle.dump(positive_texts, f)\n",
    "with open('negative_texts.pkl', 'wb') as f:\n",
    "    pickle.dump(negative_texts, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22357d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "labels = [0] * 400 + [1] * 400\n",
    "texts = negative_texts[:400] + positive_texts[:400]\n",
    "\n",
    "ds = Dataset.from_dict({\"text\": texts, \"label\": labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1859d449",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee02378",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs336-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
