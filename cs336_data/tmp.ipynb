{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3ca71e1",
   "metadata": {},
   "source": [
    "## Parse and extract text from `warc` file\n",
    "1. With `fastwarc` and `resiliparse`\n",
    "    1. https://resiliparse.chatnoir.eu/en/stable/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58b5770",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastwarc import ArchiveIterator\n",
    "from resiliparse.extract.html2text import extract_plain_text\n",
    "from resiliparse.parse.encoding import detect_encoding\n",
    "\n",
    "def extract_text(record):\n",
    "    byte_string = record.reader.read()\n",
    "    encoding = detect_encoding(byte_string)\n",
    "    html_content = byte_string.decode(encoding=encoding)\n",
    "    extracted_text = extract_plain_text(html_content)\n",
    "    return extracted_text\n",
    "\n",
    "warc_file = \"/home/azureuser/localfiles/cs336-assignment4-data-mine/cs336_data/CC-MAIN-20250417135010-20250417165010-00065.warc.gz\"\n",
    "iterator = ArchiveIterator(open(warc_file, \"rb\"), func_filter=lambda r: r.headers.get('WARC-Identified-Payload-Type') == 'text/html')\n",
    "\n",
    "# record = next(iterator)\n",
    "# print(extract_text(record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebca25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get random records for ensuing tests\n",
    "# Method: Skip randomly through iterator\n",
    "import random\n",
    "\n",
    "def get_random_records(iterator, N=20, skip_prob=0.9):\n",
    "    \"\"\"Skip records randomly and return extracted text immediately\"\"\"\n",
    "    random_data = []\n",
    "    for i, record in enumerate(iterator):\n",
    "        if len(random_data) >= N:\n",
    "            break\n",
    "        if random.random() > skip_prob:\n",
    "            # Read and process immediately while record is still fresh\n",
    "            extracted_text = extract_text(record)\n",
    "            random_data.append((i, extracted_text))\n",
    "    return random_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f449b6",
   "metadata": {},
   "source": [
    "## Language identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d05aa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "model = fasttext.load_model(\"lid.176.bin\")\n",
    "\n",
    "# sanity check\n",
    "model.predict(\"Hello world.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe62814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_generator():\n",
    "    for i, text in random_data:\n",
    "        print(f\"=== Record {i} ===\")\n",
    "        print(text[:200] + \"...\" if len(text) > 200 else text)\n",
    "        lang, score = model.predict(text.replace(\"\\n\", \" \"))\n",
    "        print(f\"Language: {lang[0]}, Score: {score[0]:.4f}\")\n",
    "        print(\"-\" * 50)\n",
    "        yield \n",
    "\n",
    "# Get random records with extracted text\n",
    "random_data = get_random_records(iterator)\n",
    "\n",
    "# Create the generator\n",
    "lang_gen = language_generator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dbf177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell multiple times to get one result at a time\n",
    "next(lang_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc4f272",
   "metadata": {},
   "source": [
    "## PII\n",
    "### email address\n",
    "- Length: The total length of an email address is capped at 320 characters, with 64 for the username and 255 for the domain.\n",
    "- Spaces: Spaces are not allowed.\n",
    "- Case sensitivity: Email addresses are generally not case-sensitive, meaning User@Example.com is the same as user@example.com.\n",
    "\n",
    "- Special characters:\n",
    "    - Periods (.), hyphens (-), and underscores (_) are often allowed in the local part.\n",
    "    - They cannot be the first or last character of the local part and cannot appear consecutively (e.g., john..doe@example.com is invalid).\n",
    "    - In the domain, hyphens are allowed but not at the beginning or end of a label (a part between periods). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3161958",
   "metadata": {},
   "source": [
    "### US phone number\n",
    "1. use pattern\n",
    "    - (\\+1\\s*)? - optional `+1` followed by optional spaces\n",
    "    - \\(? - optional opening parenthesis\n",
    "    - \\d{3} - 3 digits\n",
    "    - \\)? - optional closing parenthesis\n",
    "    - [\\s-]? - at most one space or hyphen (the ? means zero or one)\n",
    "    - \\s* - zero or more additional spaces\n",
    "    - \\d{3} - 3 digits\n",
    "    - [\\s-]? - at most one space or hyphen\n",
    "    - \\s* - zero or more additional spaces\n",
    "    - \\d{4} - 4 digits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3691ca",
   "metadata": {},
   "source": [
    "### IP address\n",
    "- Use `\\b` to avoid matching things like:\n",
    "    - 1.2.3.4.5 (too many octets)\n",
    "    - version1.2.3.4 (prefix attached)\n",
    "    - 1.2.3.4th (suffix attached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580a8216",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mask_pii import mask_email, mask_phone, mask_ip\n",
    "\n",
    "record = next(iterator)\n",
    "text = extract_text(record)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26db5fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text, mask_email_counts = mask_email(text)\n",
    "text, mask_phone_counts = mask_phone(text)\n",
    "text, mask_ip_counts = mask_ip(text)\n",
    "\n",
    "if any([counts > 0 for counts in [mask_email_counts, mask_phone_counts, mask_ip_counts]]):\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7d571a",
   "metadata": {},
   "source": [
    "## Harmful content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe55101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "\n",
    "model = fasttext.load_model(\"/home/azureuser/localfiles/cs336-assignment4-data-mine/cs336_data/jigsaw_fasttext_bigrams_nsfw_final.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1964b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\n",
    "    \"SUCK MY C*CK WIKIPEDIA EDITORS...F*CKING *SSH*LE DORKS. \"\n",
    "    \"JUST TRYING TO MAKE THE SITE BETTER YOU UPTIGHT C*NTS\"\n",
    ")\n",
    "# text = \"Umm, theres no actual article for prostitution ring.  - Crunch Captain.\"\n",
    "text = \"操你妈 你个傻逼 干死你\"\n",
    "\n",
    "model.predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df020d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b548985e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from harmful_content import classify_nsfw, classify_toxic_speech\n",
    "\n",
    "found = False\n",
    "while found == False:\n",
    "    record = next(iterator)\n",
    "    try:\n",
    "        text = extract_text(record)\n",
    "    except UnicodeDecodeError:\n",
    "        continue\n",
    "    # print(text)\n",
    "    is_nsfw, score_nsfw = classify_nsfw(text)\n",
    "    is_toxic, score_toxic = classify_toxic_speech(text)\n",
    "\n",
    "    if is_nsfw == \"nsfw\" or is_toxic == \"toxic\":\n",
    "        print(text)\n",
    "        print(\"=\"*80)\n",
    "        print(\"Harmful content detected!\")\n",
    "        print(is_nsfw, is_toxic)\n",
    "        print(score_nsfw, score_toxic)\n",
    "\n",
    "        found = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fbea20",
   "metadata": {},
   "source": [
    "## Quality Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fedcbfc",
   "metadata": {},
   "source": [
    "- To get positive texts; the filtering might be a bit cheating...\n",
    "    - `cat enwiki-20240420-extracted_urls.txt | grep \"https://en.wikipedia.org/wiki\" > enwiki-20240420-extracted_urls_subset.txt`\n",
    "    - `wget --tries=2 --timeout=5 -i enwiki-20240420-extracted_urls_subset.txt --warc-file=subsampled_positive_urls -O /dev/null`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f5bf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastwarc import ArchiveIterator\n",
    "from fastwarc.warc import WarcRecord\n",
    "from resiliparse.extract.html2text import extract_plain_text\n",
    "from resiliparse.parse.encoding import detect_encoding\n",
    "\n",
    "def extract_text(record):\n",
    "    byte_string = record.reader.read()\n",
    "    encoding = detect_encoding(byte_string)\n",
    "    try:\n",
    "        html_content = byte_string.decode(encoding=encoding)\n",
    "    except UnicodeDecodeError:\n",
    "        return \"\"\n",
    "    extracted_text = extract_plain_text(html_content)\n",
    "    return extracted_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0813af3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_html_record(record: WarcRecord) -> bool:\n",
    "    try:\n",
    "        return record.http_headers.get('Content-Type', '').startswith('text/html')\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "warc_file = \"/home/azureuser/localfiles/cs336-assignment4-data-mine/cs336_data/subsampled_positive_urls.warc.gz\"\n",
    "iterator = ArchiveIterator(open(warc_file, \"rb\"))\n",
    "\n",
    "from language_identification import identify_language\n",
    "positive_texts = []\n",
    "for record in iterator:\n",
    "    if is_html_record(record):\n",
    "        text = extract_text(record)\n",
    "        if len(text) > 512:  # very low bar for wikipedia articles\n",
    "            lang, score = identify_language(text)\n",
    "            if lang == \"en\" and score > 0.8:\n",
    "                positive_texts.append(text)\n",
    "\n",
    "print(f\"Raw number of positive texts: {len(positive_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc27014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from language_identification import identify_language\n",
    "\n",
    "def get_random_english_records_as_negative_texts(iterator, N=500, skip_prob=0.8):\n",
    "    \"\"\"Skip records randomly and return extracted text immediately\"\"\"\n",
    "    random_data = []\n",
    "    for record in iterator:\n",
    "        if len(random_data) >= N:\n",
    "            break\n",
    "        if random.random() > skip_prob:\n",
    "            # Read and process immediately while record is still fresh\n",
    "            extracted_text = extract_text(record)\n",
    "            lang, score = identify_language(extracted_text)\n",
    "            if lang == \"en\" and score > 0.9:\n",
    "                random_data.append(extracted_text)\n",
    "    return random_data\n",
    "\n",
    "warc_file = \"/home/azureuser/localfiles/cs336-assignment4-data-mine/cs336_data/CC-MAIN-20250417135010-20250417165010-00065.warc.gz\"\n",
    "iterator = ArchiveIterator(open(warc_file, \"rb\"), func_filter=lambda r: r.headers.get('WARC-Identified-Payload-Type') == 'text/html')\n",
    "negative_texts = get_random_english_records_as_negative_texts(iterator)\n",
    "\n",
    "print(f\"Raw number of negative texts: {len(negative_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bce6d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "\n",
    "def chunk_text_simple(text, tokenizer, max_length=512, stride=64):\n",
    "    \"\"\"Simpler version using return_overflowing_tokens\"\"\"\n",
    "    tokens = tokenizer(\n",
    "        text,\n",
    "        max_length=max_length,\n",
    "        stride=stride,\n",
    "        truncation=True,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    \n",
    "    return [\n",
    "        {\n",
    "            'input_ids': tokens['input_ids'][i].tolist(),\n",
    "            'attention_mask': tokens['attention_mask'][i].tolist()\n",
    "        }\n",
    "        for i in range(len(tokens['input_ids']))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc674cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_chunks = [chunk_text_simple(text, tokenizer) for text in positive_texts]\n",
    "positive_chunks = [chunk for chunks in positive_chunks for chunk in chunks]\n",
    "print(len(positive_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ed10d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_chunks = [chunk_text_simple(text, tokenizer) for text in negative_texts]\n",
    "negative_chunks = [chunk for chunks in negative_chunks for chunk in chunks]\n",
    "print(len(negative_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a060db96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle chunks before splitting\n",
    "import random\n",
    "\n",
    "random.seed(42)  # for reproducibility\n",
    "random.shuffle(negative_chunks)\n",
    "random.shuffle(positive_chunks)\n",
    "\n",
    "# Create train/valid/test splits\n",
    "n_neg = len(negative_chunks)\n",
    "n_pos = len(positive_chunks)\n",
    "\n",
    "print(f\"Total negative chunks: {n_neg}\")\n",
    "print(f\"Total positive chunks: {n_pos}\")\n",
    "\n",
    "# Split indices\n",
    "train_neg = negative_chunks[:500]\n",
    "valid_neg = negative_chunks[500:600]\n",
    "\n",
    "train_pos = positive_chunks[:500]\n",
    "valid_pos = positive_chunks[500:600]\n",
    "\n",
    "# Create datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "train_chunks = train_neg + train_pos\n",
    "train_labels = [0] * len(train_neg) + [1] * len(train_pos)\n",
    "\n",
    "valid_chunks = valid_neg + valid_pos\n",
    "valid_labels = [0] * len(valid_neg) + [1] * len(valid_pos)\n",
    "\n",
    "ds_train = Dataset.from_dict({\n",
    "    \"input_ids\": [chunk['input_ids'] for chunk in train_chunks],\n",
    "    \"attention_mask\": [chunk['attention_mask'] for chunk in train_chunks],\n",
    "    \"label\": train_labels\n",
    "})\n",
    "\n",
    "ds_valid = Dataset.from_dict({\n",
    "    \"input_ids\": [chunk['input_ids'] for chunk in valid_chunks],\n",
    "    \"attention_mask\": [chunk['attention_mask'] for chunk in valid_chunks],\n",
    "    \"label\": valid_labels\n",
    "})\n",
    "\n",
    "print(f\"\\nTrain: {len(ds_train)} samples (neg: {sum(1 for l in train_labels if l == 0)}, pos: {sum(1 for l in train_labels if l == 1)})\")\n",
    "print(f\"Valid: {len(ds_valid)} samples (neg: {sum(1 for l in valid_labels if l == 0)}, pos: {sum(1 for l in valid_labels if l == 1)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22bc176",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d0113e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"quality_classifier\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds_train,\n",
    "    eval_dataset=ds_valid,\n",
    "    processing_class=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a77cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/azureuser/localfiles/cs336-assignment4-data-mine/tests/fixtures/high_quality_wiki_reference.txt\") as f:\n",
    "    hq_text = f.read()\n",
    "with open(\"/home/azureuser/localfiles/cs336-assignment4-data-mine/tests/fixtures/low_quality_cc.txt\") as f:\n",
    "    lq_text = f.read()\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "# hq_text = \"This was a masterpiece. Not completely faithful to the books, but enthralling from beginning to end. Might be my favorite of the three.\"\n",
    "hq_text = 'Anarchism\\nFirst published Tue Oct 3, 2017; substantive revision Tue Oct 26, 2021\\nAnarchism is a political theory that is skeptical of the justification of authority and power. Anarchism is usually grounded in moral claims about the importance of individual liberty, often conceived as freedom from domination. Anarchists also offer a positive theory of human flourishing, based upon an ideal of equality, community, and non-coercive consensus building. Anarchism has inspired practical efforts at establishing utopian communities, radical and revolutionary political agendas, and various forms of direct action. This entry primarily describes “philosophical anarchism”: it focuses on anarchism as a theoretical idea and not as a form of political activism. While philosophical anarchism describes a skeptical theory of political legitimation, anarchism is also a concept that has been employed in philosophical and literary theory to describe a sort of anti-foundationalism. Philosophical anarchism can mean either a theory of political life that is skeptical of attempts to justify state authority or a philosophical theory that is skeptical of the attempt to assert firm foundations for knowledge.\\n\\n1. Varieties of Anarchism\\nThere are various forms of anarchism. Uniting this variety is the general critique of centralized, hierarchical power and authority.'\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "# classifier = pipeline(\"sentiment-analysis\", model=\"quality_classifier/checkpoint-152\")\n",
    "classifier(hq_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff11767b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lq_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs336-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
